{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkLEqzRXs_dL",
        "outputId": "9a73b3a7-d444-4460-c834-313bf3520429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vu1vHJ5es7Do",
        "outputId": "9db205da-9b35-41ea-8839-2f7de5c49138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted /content/drive/MyDrive/빅데이터응용보안/trec07p.tar to /content/drive/MyDrive/빅데이터응용보안/trec07\n"
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "\n",
        "def extract_tar_file(tar_path='/content/drive/MyDrive/빅데이터응용보안/trec07p.tar', extract_path='/content/drive/MyDrive/빅데이터응용보안/trec07'):\n",
        "    \"\"\"\n",
        "    Extracts a tar file to a specified directory.\n",
        "\n",
        "    Args:\n",
        "    tar_path (str): The path to the tar file.\n",
        "    extract_path (str): The directory to extract the files into. Defaults to the current directory.\n",
        "    \"\"\"\n",
        "    with tarfile.open(tar_path, 'r') as tar:\n",
        "        tar.extractall(path=extract_path)\n",
        "        print(f\"Extracted {tar_path} to {extract_path}\")\n",
        "\n",
        "extract_tar_file('/content/drive/MyDrive/빅데이터응용보안/trec07p.tar')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/빅데이터응용보안/trec07/trec07p/data/'\n",
        "LABELS_FILE = '/content/drive/MyDrive/빅데이터응용보안/trec07/trec07p/full/index'\n",
        "TRAINING_SET_RATIO = 0.7"
      ],
      "metadata": {
        "id": "fM4MLnWwuYJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {}\n",
        "# Read the labels\n",
        "with open(LABELS_FILE) as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        label, key = line.split()\n",
        "        labels[key.split('/')[-1]] = 1 if label.lower() == 'ham' else 0"
      ],
      "metadata": {
        "id": "sh7etFvKuYPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_email_files():\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(labels)):\n",
        "        filename = 'inmail.' + str(i+1)\n",
        "        email_str = email_read_util.extract_email_text(\n",
        "            os.path.join(DATA_DIR, filename))\n",
        "        X.append(email_str)\n",
        "        y.append(labels[filename])\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "QTqTJLenuYS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "#email_read_util을 불러오기 위함"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl0VBQE7064k",
        "outputId": "0e940513-62cc-4409-a3c2-7d8d09b07673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/빅데이터응용보안/trec07/\n",
        "import email_read_util\n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRzzKCM_0nrX",
        "outputId": "7e746f8e-c4ad-4bfa-cb9c-f1a7264369c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/빅데이터응용보안/trec07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = read_email_files()"
      ],
      "metadata": {
        "id": "3yaTzqCluakI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN 모델 build 과정"
      ],
      "metadata": {
        "id": "znXQEMY3Fj6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dropout, Dense\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, num_filters, kernel_size, pool_size, dropout_rate, dense_units, num_conv_layers):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embedding_dim, input_length=1000))  # Character를 Embedding할 layer\n",
        "\n",
        "    # convolutional layer와 pooling layers 추가\n",
        "    for _ in range(num_conv_layers):\n",
        "        model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
        "        model.add(MaxPooling1D(pool_size))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(dense_units, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# model parameter\n",
        "VOCAB_SIZE = 256  # ASCII 문자: 256 size\n",
        "EMBEDDING_DIM = 50\n",
        "NUM_FILTERS = 64\n",
        "KERNEL_SIZE = 3\n",
        "POOL_SIZE = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "DENSE_UNITS = 256\n",
        "NUM_CONV_LAYERS = 5\n",
        "\n",
        "# 모델 빌드\n",
        "cnn_model = build_model(VOCAB_SIZE, EMBEDDING_DIM, NUM_FILTERS, KERNEL_SIZE, POOL_SIZE, DROPOUT_RATE, DENSE_UNITS, NUM_CONV_LAYERS)\n",
        "cnn_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vne-kVuZtOqs",
        "outputId": "1761f3ae-9f1c-40c3-835c-c45587633013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 1000, 50)          12800     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 998, 64)           9664      \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 499, 64)           0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 497, 64)           12352     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 248, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 246, 64)           12352     \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 123, 64)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 121, 64)           12352     \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 60, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 58, 64)            12352     \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPoolin  (None, 29, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1856)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1856)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               475392    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 547521 (2.09 MB)\n",
            "Trainable params: 547521 (2.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocess_email(text):\n",
        "    #텍스트 전처리: 1. HTML tag 제거, 2. 소문자로 일괄 변환, 3. 특수문자 제거\n",
        "    text = tf.strings.regex_replace(text, \"<[^>]+>\", \" \")  # HTML tag 제거\n",
        "    text = tf.strings.regex_replace(text, \"[^a-zA-Z0-9 ]\", \"\")  # 특수문자\n",
        "    text = tf.strings.lower(text) #소문자\n",
        "    return text\n",
        "\n",
        "# X: raw email text data, y : 0과 1로 된 list\n",
        "X_clean = [preprocess_email(email).numpy().decode('utf-8') for email in X]\n",
        "\n",
        "# character embedding : 문자 index mapping으로 text를 인코딩하기\n",
        "char_index = {chr(i): i for i in range(256)}  # text를 character 중 ASCII(256) 로 매핑하기\n",
        "\n",
        "def encode_texts(texts, max_length=1000):\n",
        "    #text를 padding된 integer로 encode함\n",
        "    encoded = [[char_index.get(char, 0) for char in text] for text in texts]\n",
        "    return pad_sequences(encoded, maxlen=max_length, padding='post', truncating='post')\n",
        "\n",
        "X_encoded = encode_texts(X_clean)\n",
        "\n",
        "# X,y를 일괄 encoding하고 나서 split하기\n",
        "TRAINING_SET_RATIO = 0.7\n",
        "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
        "    X_encoded, y, range(len(y)),\n",
        "    train_size=TRAINING_SET_RATIO, random_state=2\n",
        ")\n",
        "\n",
        "#array 형태로 바꿔줘야 train이 됨.\n",
        "y_train2 = np.array(y_train)\n",
        "y_test2 = np.array(y_test)\n",
        "\n",
        "# 모델 train\n",
        "cnn_model.fit(X_train, y_train2, epochs=50, validation_data=(X_test, y_test2))\n",
        "#epoch 100이 원본 파라미터이나, 성능에 차이가 없어 50으로 하향 조정\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzBtmG4L2vUG",
        "outputId": "98e2ee69-ff58-4ee4-cd90-124ebf842ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.1487 - val_accuracy: 0.9874\n",
            "Epoch 2/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0082 - accuracy: 0.9980 - val_loss: 0.1033 - val_accuracy: 0.9907\n",
            "Epoch 3/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0132 - accuracy: 0.9972 - val_loss: 0.1274 - val_accuracy: 0.9903\n",
            "Epoch 4/50\n",
            "1650/1650 [==============================] - 17s 10ms/step - loss: 0.0081 - accuracy: 0.9981 - val_loss: 0.0850 - val_accuracy: 0.9909\n",
            "Epoch 5/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0152 - accuracy: 0.9973 - val_loss: 0.0700 - val_accuracy: 0.9910\n",
            "Epoch 6/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1033 - val_accuracy: 0.9913\n",
            "Epoch 7/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.0886 - val_accuracy: 0.9900\n",
            "Epoch 8/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0091 - accuracy: 0.9980 - val_loss: 0.0669 - val_accuracy: 0.9901\n",
            "Epoch 9/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0086 - accuracy: 0.9982 - val_loss: 0.1166 - val_accuracy: 0.9897\n",
            "Epoch 10/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0105 - accuracy: 0.9973 - val_loss: 0.1205 - val_accuracy: 0.9897\n",
            "Epoch 11/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0691 - val_accuracy: 0.9901\n",
            "Epoch 12/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 0.0936 - val_accuracy: 0.9895\n",
            "Epoch 13/50\n",
            "1650/1650 [==============================] - 17s 10ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0964 - val_accuracy: 0.9910\n",
            "Epoch 14/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0114 - accuracy: 0.9973 - val_loss: 0.0866 - val_accuracy: 0.9905\n",
            "Epoch 15/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.0960 - val_accuracy: 0.9901\n",
            "Epoch 16/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 0.0913 - val_accuracy: 0.9907\n",
            "Epoch 17/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0130 - accuracy: 0.9977 - val_loss: 0.0754 - val_accuracy: 0.9895\n",
            "Epoch 18/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0898 - val_accuracy: 0.9910\n",
            "Epoch 19/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0174 - accuracy: 0.9964 - val_loss: 0.1043 - val_accuracy: 0.9903\n",
            "Epoch 20/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.1291 - val_accuracy: 0.9879\n",
            "Epoch 21/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0174 - accuracy: 0.9970 - val_loss: 0.0681 - val_accuracy: 0.9902\n",
            "Epoch 22/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0893 - val_accuracy: 0.9908\n",
            "Epoch 23/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.2683 - val_accuracy: 0.9878\n",
            "Epoch 24/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0161 - accuracy: 0.9976 - val_loss: 0.1502 - val_accuracy: 0.9901\n",
            "Epoch 25/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 0.0921 - val_accuracy: 0.9890\n",
            "Epoch 26/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.1244 - val_accuracy: 0.9902\n",
            "Epoch 27/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.1643 - val_accuracy: 0.9902\n",
            "Epoch 28/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.1489 - val_accuracy: 0.9883\n",
            "Epoch 29/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0058 - accuracy: 0.9983 - val_loss: 0.2077 - val_accuracy: 0.9905\n",
            "Epoch 30/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.1192 - val_accuracy: 0.9893\n",
            "Epoch 31/50\n",
            "1650/1650 [==============================] - 17s 10ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.1112 - val_accuracy: 0.9863\n",
            "Epoch 32/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.1188 - val_accuracy: 0.9898\n",
            "Epoch 33/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0137 - accuracy: 0.9975 - val_loss: 0.1184 - val_accuracy: 0.9889\n",
            "Epoch 34/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 0.1911 - val_accuracy: 0.9890\n",
            "Epoch 35/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.1416 - val_accuracy: 0.9777\n",
            "Epoch 36/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 0.1339 - val_accuracy: 0.9904\n",
            "Epoch 37/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.2066 - val_accuracy: 0.9901\n",
            "Epoch 38/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0212 - accuracy: 0.9973 - val_loss: 0.1151 - val_accuracy: 0.9901\n",
            "Epoch 39/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.1895 - val_accuracy: 0.9901\n",
            "Epoch 40/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0129 - accuracy: 0.9976 - val_loss: 0.1790 - val_accuracy: 0.9890\n",
            "Epoch 41/50\n",
            "1650/1650 [==============================] - 17s 10ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.2830 - val_accuracy: 0.9900\n",
            "Epoch 42/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.2840 - val_accuracy: 0.9905\n",
            "Epoch 43/50\n",
            "1650/1650 [==============================] - 16s 10ms/step - loss: 0.0087 - accuracy: 0.9984 - val_loss: 0.2544 - val_accuracy: 0.9903\n",
            "Epoch 44/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0078 - accuracy: 0.9983 - val_loss: 0.1854 - val_accuracy: 0.9887\n",
            "Epoch 45/50\n",
            "1650/1650 [==============================] - 16s 9ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.4186 - val_accuracy: 0.9890\n",
            "Epoch 46/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0165 - accuracy: 0.9968 - val_loss: 0.1492 - val_accuracy: 0.9891\n",
            "Epoch 47/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.2386 - val_accuracy: 0.9899\n",
            "Epoch 48/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.1169 - val_accuracy: 0.9891\n",
            "Epoch 49/50\n",
            "1650/1650 [==============================] - 15s 9ms/step - loss: 0.0096 - accuracy: 0.9980 - val_loss: 0.3388 - val_accuracy: 0.9893\n",
            "Epoch 50/50\n",
            "1650/1650 [==============================] - 17s 10ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.1310 - val_accuracy: 0.9896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f236c2d6fe0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbouVv3D_ju3",
        "outputId": "bdc88e69-4474-47ab-82b5-14c15bf81b14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52793"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddHUXxod_lXb",
        "outputId": "16cb845a-e3bc-4b53-c5ba-e62d43674534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22626"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#cnn model predict된 결과는 마지막 sigmoid 함수의 결과로 probability로 나온다.\n",
        "#그렇기에 0.5 이하인 확률을 0, 0.5 이상인 확률을 1로 변환해준다.\n",
        "y_pred_prob = cnn_model.predict(X_test)\n",
        "y_pred_class = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "precision = precision_score(y_test, y_pred_class)\n",
        "recall = recall_score(y_test, y_pred_class)\n",
        "accuracy = accuracy_score(y_test, y_pred_class)\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAZkPk6JAjEh",
        "outputId": "2292b548-b87a-411d-ca97-1a06cb37b86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "708/708 [==============================] - 2s 3ms/step\n",
            "Precision: 0.99\n",
            "Recall: 0.98\n",
            "Accuracy: 0.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test,y_pred_class,target_names=['Spam','Ham']))\n",
        "print('Classification accuracy {:.1%}'.format(accuracy_score(y_test,y_pred_class)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK_msZtAFAXA",
        "outputId": "d32751c5-c30f-4153-c441-ce3cdd683c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Spam       0.99      1.00      0.99     15035\n",
            "         Ham       0.99      0.98      0.98      7591\n",
            "\n",
            "    accuracy                           0.99     22626\n",
            "   macro avg       0.99      0.99      0.99     22626\n",
            "weighted avg       0.99      0.99      0.99     22626\n",
            "\n",
            "Classification accuracy 99.0%\n"
          ]
        }
      ]
    }
  ]
}